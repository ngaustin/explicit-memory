{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.join(sys.path[0], \"..\"))\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w01 w03episode w02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w05    w001 episode "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  episode w06episode w09     w07reward 13.054 3reward 13.0   episode w08\n",
      "episode 2   reward 13.0\n",
      "episode 6 \n",
      " reward 14.0reward 13.0\n",
      "\n",
      " reward 12.0 \n",
      "9episode 8w01  w06  episode 7reward 13.0  \n",
      "13w05reward 13.0 \n",
      "reward 9.0 \n",
      "episode w02  16reward 12.0 episode \n",
      "reward 9.0w00\n",
      " episode  17  w08episode reward 10.0  \n",
      "episode w0914  18episode    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w11 19episode w05reward 9.0  10 reward 12.0reward 10.0  \n",
      "reward 10.0episode \n",
      "11\n",
      "w00 episode w13\n",
      "w12  w11 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/dev-python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:95: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode reward 9.0  episode  20episode 21  15reward 10.0 reward 15.0 \n",
      "w09 episode   \n",
      "reward 10.0\n",
      " 2212w02 reward 10.0 23 reward 10.0\n",
      "w01\n",
      "w00  \n",
      "episode w05  episode  episode 27 reward 10.0\n",
      " episode w1325reward 13.0 24 \n",
      "reward 10.0w05    episode  26\n",
      "episode 28 reward 9.0reward 10.0\n",
      " \n",
      "w01 reward 9.0episode  \n",
      "30 reward 10.0\n",
      " w01 episode 29  reward 8.031\n",
      " w05 episode  reward 10.032 reward 9.0\n",
      "\n",
      "w01 episode  33 reward 10.0\n",
      "w01 episode  34 reward 10.0\n",
      "w01 episode  35 reward 8.0\n",
      "w01 episode  36 reward 9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code is heavily inspired by Morvan Zhou's code. Please check out\n",
    "# his work at github.com/MorvanZhou/pytorch-A3C\n",
    "import gym\n",
    "import torch as T\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "class SharedAdam(T.optim.Adam):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8,\n",
    "            weight_decay=0):\n",
    "        super(SharedAdam, self).__init__(params, lr=lr, betas=betas, eps=eps,\n",
    "                weight_decay=weight_decay)\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                state = self.state[p]\n",
    "                state['step'] = 0\n",
    "                state['exp_avg'] = T.zeros_like(p.data)\n",
    "                state['exp_avg_sq'] = T.zeros_like(p.data)\n",
    "\n",
    "                state['exp_avg'].share_memory_()\n",
    "                state['exp_avg_sq'].share_memory_()\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, input_dims, n_actions, gamma=0.99):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.pi1 = nn.Linear(*input_dims, 128)\n",
    "        self.v1 = nn.Linear(*input_dims, 128)\n",
    "        self.pi = nn.Linear(128, n_actions)\n",
    "        self.v = nn.Linear(128, 1)\n",
    "\n",
    "        self.rewards = []\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "\n",
    "    def remember(self, state, action, reward):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, state):\n",
    "        pi1 = F.relu(self.pi1(state))\n",
    "        v1 = F.relu(self.v1(state))\n",
    "\n",
    "        pi = self.pi(pi1)\n",
    "        v = self.v(v1)\n",
    "\n",
    "        return pi, v\n",
    "\n",
    "    def calc_R(self, done):\n",
    "        states = T.tensor(self.states, dtype=T.float)\n",
    "        _, v = self.forward(states)\n",
    "\n",
    "        R = v[-1]*(1-int(done))\n",
    "\n",
    "        batch_return = []\n",
    "        for reward in self.rewards[::-1]:\n",
    "            R = reward + self.gamma*R\n",
    "            batch_return.append(R)\n",
    "        batch_return.reverse()\n",
    "        batch_return = T.tensor(batch_return, dtype=T.float)\n",
    "\n",
    "        return batch_return\n",
    "\n",
    "    def calc_loss(self, done):\n",
    "        states = T.tensor(self.states, dtype=T.float)\n",
    "        actions = T.tensor(self.actions, dtype=T.float)\n",
    "\n",
    "        returns = self.calc_R(done)\n",
    "\n",
    "        pi, values = self.forward(states)\n",
    "        values = values.squeeze()\n",
    "        critic_loss = (returns-values)**2\n",
    "\n",
    "        probs = T.softmax(pi, dim=1)\n",
    "        dist = Categorical(probs)\n",
    "        log_probs = dist.log_prob(actions)\n",
    "        actor_loss = -log_probs*(returns-values)\n",
    "\n",
    "        total_loss = (critic_loss + actor_loss).mean()\n",
    "    \n",
    "        return total_loss\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        state = T.tensor([observation], dtype=T.float)\n",
    "        pi, v = self.forward(state)\n",
    "        probs = T.softmax(pi, dim=1)\n",
    "        dist = Categorical(probs)\n",
    "        action = dist.sample().numpy()[0]\n",
    "\n",
    "        return action\n",
    "\n",
    "class Agent(mp.Process):\n",
    "    def __init__(self, global_actor_critic, optimizer, input_dims, n_actions, \n",
    "                gamma, lr, name, global_ep_idx, env_id):\n",
    "        super(Agent, self).__init__()\n",
    "        self.local_actor_critic = ActorCritic(input_dims, n_actions, gamma)\n",
    "        self.global_actor_critic = global_actor_critic\n",
    "        self.name = 'w%02i' % name\n",
    "        self.episode_idx = global_ep_idx\n",
    "        self.env = gym.make(env_id)\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def run(self):\n",
    "        t_step = 1\n",
    "        while self.episode_idx.value < N_GAMES:\n",
    "            done = False\n",
    "            observation = self.env.reset()\n",
    "            score = 0\n",
    "            self.local_actor_critic.clear_memory()\n",
    "            while not done:\n",
    "                action = self.local_actor_critic.choose_action(observation)\n",
    "                observation_, reward, done, info = self.env.step(action)\n",
    "                score += reward\n",
    "                self.local_actor_critic.remember(observation, action, reward)\n",
    "                if t_step % T_MAX == 0 or done:\n",
    "                    loss = self.local_actor_critic.calc_loss(done)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    for local_param, global_param in zip(\n",
    "                            self.local_actor_critic.parameters(),\n",
    "                            self.global_actor_critic.parameters()):\n",
    "                        global_param._grad = local_param.grad\n",
    "                    self.optimizer.step()\n",
    "                    self.local_actor_critic.load_state_dict(\n",
    "                            self.global_actor_critic.state_dict())\n",
    "                    self.local_actor_critic.clear_memory()\n",
    "                t_step += 1\n",
    "                observation = observation_\n",
    "            with self.episode_idx.get_lock():\n",
    "                self.episode_idx.value += 1\n",
    "            print(self.name, 'episode ', self.episode_idx.value, 'reward %.1f' % score)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lr = 1e-4\n",
    "    env_id = 'CartPole-v0'\n",
    "    n_actions = 2\n",
    "    input_dims = [4]\n",
    "    N_GAMES = 3000\n",
    "    T_MAX = 5\n",
    "    global_actor_critic = ActorCritic(input_dims, n_actions)\n",
    "    global_actor_critic.share_memory()\n",
    "    optim = SharedAdam(global_actor_critic.parameters(), lr=lr, \n",
    "                        betas=(0.92, 0.999))\n",
    "    global_ep = mp.Value('i', 0)\n",
    "\n",
    "    workers = [Agent(global_actor_critic,\n",
    "                    optim,\n",
    "                    input_dims,\n",
    "                    n_actions,\n",
    "                    gamma=0.99,\n",
    "                    lr=lr,\n",
    "                    name=i,\n",
    "                    global_ep_idx=global_ep,\n",
    "                    env_id=env_id) for i in range(mp.cpu_count())]\n",
    "    [w.start() for w in workers]\n",
    "    [w.join() for w in workers]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory.model import Embeddings, MLP\n",
    "from memory.utils import read_yaml\n",
    "\n",
    "config = read_yaml(\"./train.yaml\")\n",
    "\n",
    "# embeddings = Embeddings(\n",
    "#     generator_params=config[\"generator_params\"],\n",
    "#     embedding_dim=1,\n",
    "#     num_rows=128,\n",
    "#     num_cols=3,\n",
    "# )\n",
    "\n",
    "model = MLP(\n",
    "    capacity={\"episodic\": 128, \"semantic\": 0},\n",
    "    policy_type=\"episodic_memory_manage\",\n",
    "    embedding_dim=4,\n",
    "    generator_params=config[\"generator_params\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory import EpisodicMemory\n",
    "\n",
    "M_e = EpisodicMemory(128)\n",
    "\n",
    "from memory.environment.gym import MemoryEnv\n",
    "\n",
    "env = MemoryEnv(**config[\"generator_params\"])\n",
    "env.reset()\n",
    "\n",
    "while not M_e.is_kinda_full:\n",
    "    oq = env.step('foo')[0]\n",
    "    ob = oq['observation']\n",
    "    question = oq['question']\n",
    "    M_e.add(M_e.ob2epi(ob))\n",
    "\n",
    "# embs = embeddings.episodic2numerics(M_e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index to remove: 68\t state-action value: 0.707\t \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0856, -0.3869, -0.0901, -0.2366,  0.0682, -0.4274,  0.0169,  0.1619,\n",
       "         -0.4676, -0.0910,  0.4621,  0.2447,  0.0404,  0.1040, -0.3926, -0.0018,\n",
       "          0.0351, -0.3278, -0.2818,  0.0983, -0.1878, -0.3582, -0.0318,  0.0497,\n",
       "         -0.2144,  0.5740, -0.1171,  0.2608, -0.2146,  0.2797, -0.4012,  0.0017,\n",
       "         -0.2335,  0.3251, -0.7201,  0.3027, -0.2612, -0.3721, -0.7480,  0.2036,\n",
       "          0.0607, -0.1806, -0.0503,  0.2271,  0.4500, -0.2716,  0.1911, -0.1372,\n",
       "          0.3027,  0.1787,  0.1552,  0.3989,  0.1689, -0.0118, -0.3794,  0.3928,\n",
       "         -0.1634, -0.2065,  0.1683, -0.1849,  0.1682,  0.3359, -0.3104,  0.4516,\n",
       "         -0.3968,  0.1173,  0.3788,  0.4869,  0.7070, -0.0192, -0.0306,  0.0561,\n",
       "          0.2972,  0.0678, -0.3050,  0.4067,  0.4943,  0.0360, -0.1547,  0.1804,\n",
       "         -0.2899,  0.0721, -0.4985, -0.1409, -0.1949, -0.0859, -0.3418,  0.2222,\n",
       "         -0.0440,  0.2541, -0.1954,  0.1354, -0.1773,  0.4508,  0.0229, -0.2044,\n",
       "         -0.1044,  0.1943, -0.6646, -0.2634,  0.6543,  0.6047, -0.3551, -0.0425,\n",
       "          0.1496, -0.0451, -0.0670, -0.0424,  0.1492,  0.0589,  0.3491,  0.3896,\n",
       "          0.0866, -0.0759,  0.2311,  0.4068, -0.0570, -0.0432, -0.0224,  0.0309,\n",
       "         -0.3561,  0.1172,  0.4627,  0.1266, -0.0725, -0.4917, -0.1820,  0.4756,\n",
       "          0.1484]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(model.make_state(M_e, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_101029/2938571493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings.positional_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.eq2numerics(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cat([torch.tensor([1]),torch.tensor([1]),torch.tensor([1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "foo = torch.tensor([1],device='gpu')\n",
    "\n",
    "foo.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory.utils import read_yaml\n",
    "from memory.environment.gym import MemoryEnv\n",
    "from reinforcement_q_learning import Transition\n",
    "from memory.utils import write_json, seed_everything\n",
    "\n",
    "config = read_yaml(\"./train.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_yaml(\"./train.yaml\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_pytorch_example import *\n",
    "\n",
    "Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory.environment.generator import OQAGenerator\n",
    "gen_params = {\n",
    "    \"max_history\": 1024,\n",
    "    \"semantic_knowledge_path\": \"./data/semantic-knowledge.json\",\n",
    "    \"names_path\": \"./data/top-human-names\",\n",
    "    \"weighting_mode\": \"weighted\",\n",
    "    \"commonsense_prob\": 0.5,\n",
    "    \"time_start_at\": 0,\n",
    "    \"limits\": {\n",
    "        \"heads\": None,\n",
    "        \"tails\": None,\n",
    "        \"names\": None,\n",
    "        \"allow_spaces\": True,\n",
    "    },\n",
    "    \"disjoint_entities\": True,\n",
    "}\n",
    "\n",
    "oqag = OQAGenerator(**gen_params)\n",
    "\n",
    "len(oqag.heads), len(oqag.tails), len(oqag.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory.utils import read_yaml\n",
    "\n",
    "config = read_yaml('./train.yaml')\n",
    "config['generator_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory.environment.generator import OQAGenerator\n",
    "\n",
    "oqag  = OQAGenerator()\n",
    "\n",
    "len(oqag.heads), len(oqag.tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "foo = [foo for foo in range(0, 1024)]\n",
    "weights1 = foo\n",
    "weights2 = [bar ** 2 for bar in foo]\n",
    "\n",
    "num_to_sample = 10000\n",
    "\n",
    "samples1 = [\n",
    "    val / num_to_sample\n",
    "    for key, val in sorted(\n",
    "        dict(Counter(random.choices(foo, k=num_to_sample, weights=weights1))).items()\n",
    "    )\n",
    "]\n",
    "\n",
    "samples2 = [val / num_to_sample\n",
    "    for key, val in sorted(\n",
    "        dict(Counter(random.choices(foo, k=num_to_sample, weights=weights2))).items()\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(samples1)\n",
    "# plt.plot(samples2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples1), len(samples2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(random.choices(foo, k=100, weights=[2*bar for bar in foo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[2*bar for bar in foo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "probs = torch.tensor([1,2,3,4])\n",
    "m = Categorical(probs)\n",
    "action = m.sample()\n",
    "\n",
    "m, action, m.log_prob(torch.tensor(action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "bar = torch.tensor([[1]]) + torch.tensor([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar, bar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory.utils import read_yaml\n",
    "\n",
    "config = read_yaml(\"./train.yaml\")\n",
    "from memory.model import Embeddings\n",
    "\n",
    "\n",
    "embs = Embeddings(\n",
    "    generator_params=config[\"generator_params\"],\n",
    "    embedding_dim=4,\n",
    "    num_rows=129,\n",
    "    num_cols=6,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "\n",
    "for emb in embs.positional_embeddings.weight:\n",
    "    plt.plot(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "def position_encoding_init(n_position, d_pos_vec):\n",
    "    ''' Init the sinusoid position encoding table '''\n",
    "\n",
    "    # keep dim 0 for padding token position encoding zero vector\n",
    "    position_enc = np.array([\n",
    "        [pos / np.power(10000, 2*(i//2) / d_pos_vec) for i in range(d_pos_vec)]\n",
    "        if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
    "\n",
    "    position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "    position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "    return torch.from_numpy(position_enc).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "\n",
    "for row in position_encoding_init(129, 6):\n",
    "    plt.plot(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7808f786822013b9d5984aa54e12ef6bec326a79c76c0a75cd22ab652610adbd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('explicit-memory': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
