{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tk/repos/explicit-memory\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from memory.environments import OQAGenerator, MemorySpace\n",
    "from memory import Memory, EpisodicMemory, SemanticMemory\n",
    "\n",
    "\n",
    "class EpisodicMemoryManage(gym.Env):\n",
    "    \"\"\"Custom Memory environment compatiable with the gym interface.\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"console\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        capacity: dict,\n",
    "        max_history: int = 1024,\n",
    "        semantic_knowledge_path: str = \"./data/semantic-knowledge.json\",\n",
    "        names_path: str = \"./data/top-human-names\",\n",
    "        weighting_mode: str = \"highest\",\n",
    "        commonsense_prob: float = 0.5,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        capacity: memory capacity\n",
    "            e.g., {'episodic': 42, 'semantic: 0}\n",
    "        max_history: maximum history of observations.\n",
    "        semantic_knowledge_path: path to the semantic knowledge generated from\n",
    "            `collect_data.py`\n",
    "        names_path: The path to the top 20 human name list.\n",
    "        weighting_mode: \"highest\" chooses the one with the highest weight, \"weighted\"\n",
    "            chooses all of them by weight, and null chooses every single one of them\n",
    "            without weighting.\n",
    "        commonsense_prob: the probability of an observation being covered by a\n",
    "            commonsense\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert capacity[\"semantic\"] == 0\n",
    "        self.capacity = capacity\n",
    "        self.oqag = OQAGenerator(\n",
    "            max_history,\n",
    "            semantic_knowledge_path,\n",
    "            names_path,\n",
    "            weighting_mode,\n",
    "            commonsense_prob,\n",
    "        )\n",
    "        self.n_actions = self.capacity[\"episodic\"] + 1\n",
    "        self.action_space = spaces.Discrete(self.n_actions)\n",
    "        self.M_e = EpisodicMemory(self.capacity[\"episodic\"])\n",
    "        space_type = \"episodic_memory_manage\"\n",
    "        self.me_max = self.M_e.capacity + 1\n",
    "\n",
    "        self.observation_space = MemorySpace(\n",
    "            capacity,\n",
    "            space_type,\n",
    "            max_history,\n",
    "            semantic_knowledge_path,\n",
    "            names_path,\n",
    "            weighting_mode,\n",
    "            commonsense_prob,\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.oqag.reset()\n",
    "        self.M_e.forget_all()\n",
    "\n",
    "        ob, _ = self.oqag.generate(generate_qa=False)\n",
    "        mem_epi = self.M_e.ob2epi(ob)\n",
    "        self.M_e.add(mem_epi)\n",
    "\n",
    "        return self.observation_space.episodic_memory_system_to_numbers(\n",
    "            self.M_e, self.me_max\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.M_e.is_kinda_full:\n",
    "            mem_to_forget = self.M_e.entries[action]\n",
    "            self.M_e.forget(mem_to_forget)\n",
    "\n",
    "        qa = self.oqag.generate_question_answer()\n",
    "\n",
    "        reward, _, _ = self.M_e.answer_latest(qa)\n",
    "\n",
    "        if self.oqag.is_full:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        ob, _ = self.oqag.generate(generate_qa=False)\n",
    "        mem_epi = self.M_e.ob2epi(ob)\n",
    "        self.M_e.add(mem_epi)\n",
    "\n",
    "        next_state = self.observation_space.episodic_memory_system_to_numbers(\n",
    "            self.M_e, self.me_max\n",
    "        )\n",
    "\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "    def render(self, mode=\"console\"):\n",
    "        if mode != \"console\":\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            print(self.M_e.entries)\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 22:31:34.868 INFO environments - load_semantic_knowledge: semantic knowledge successfully loaded from ./data/semantic-knowledge.json!\n",
      "2021-11-23 22:31:34.869 INFO environments - read_names: Reading ./data/top-human-names complete! There are 20 names in total\n",
      "2021-11-23 22:31:34.870 INFO environments - __init__: An Observation-Question-Answer generator object is generated!\n",
      "2021-11-23 22:31:34.871 INFO environments - load_semantic_knowledge: semantic knowledge successfully loaded from ./data/semantic-knowledge.json!\n",
      "2021-11-23 22:31:34.872 INFO environments - read_names: Reading ./data/top-human-names complete! There are 20 names in total\n",
      "2021-11-23 22:31:34.872 INFO environments - __init__: An Observation-Question-Answer generator object is generated!\n"
     ]
    }
   ],
   "source": [
    "foo = EpisodicMemoryManage(capacity={'episodic':10, 'semantic': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 22:32:05.918 INFO environments - reset: Reseting the history is done!\n",
      "2021-11-23 22:32:05.919 WARNING memory - forget_all: EVERYTHING IN THE MEMORY SYSTEM WILL BE FORGOTTEN!\n",
      "2021-11-23 22:32:05.920 INFO environments - generate_observation: A new observation generated: [\"James's mouse\", 'AtLocation', \"James's closet\", 1637703125.9201865]\n",
      "2021-11-23 22:32:05.920 INFO environments - add_observation_to_history: observation [\"James's mouse\", 'AtLocation', \"James's closet\", 1637703125.9201865] is added to history!\n",
      "2021-11-23 22:32:05.920 INFO environments - generate: The new observation is added to the history.\n",
      "2021-11-23 22:32:05.921 INFO memory - ob2epi: Observation [\"James's mouse\", 'AtLocation', \"James's closet\", 1637703125.9201865] is now a episodic memory [\"James's mouse\", 'AtLocation', \"James's closet\", 1637703125.9201865]\n",
      "2021-11-23 22:32:05.921 INFO memory - add: memory entry [\"James's mouse\", 'AtLocation', \"James's closet\", 1637703125.9201865] added. Now there are in total of 1 memories!\n",
      "2021-11-23 22:32:05.921 INFO environments - episodic_memory_system_to_numbers: The episodic memory system has been converted to a numpy array!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0400000e+02, 1.0300000e+03, 1.0000000e+01, 1.0400000e+02,\n",
       "        1.0032000e+04, 1.6377032e+09],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 22:34:14.375 INFO memory - forget: [\"Jessica's bear\", 'AtLocation', \"Jessica's countryside\", 1637703211.2613502] forgotten!\n",
      "2021-11-23 22:34:14.377 INFO environments - generate_question_answer: Generated question and answer is [\"William's toothbrush\", 'AtLocation', \"William's suitcase\"]\n",
      "2021-11-23 22:34:14.377 INFO memory - is_question_valid: [\"William's toothbrush\", 'AtLocation', \"William's suitcase\"] is a valid question.\n",
      "2021-11-23 22:34:14.378 INFO memory - answer_latest: no relevant memories found.\n",
      "2021-11-23 22:34:14.378 INFO memory - answer_latest: pred: None, correct answer: suitcase. Reward: 0\n",
      "2021-11-23 22:34:14.379 INFO environments - generate_observation: A new observation generated: [\"Karen's elephant\", 'AtLocation', \"Karen's tree\", 1637703254.3793077]\n",
      "2021-11-23 22:34:14.379 INFO environments - add_observation_to_history: observation [\"Karen's elephant\", 'AtLocation', \"Karen's tree\", 1637703254.3793077] is added to history!\n",
      "2021-11-23 22:34:14.380 INFO environments - generate: The new observation is added to the history.\n",
      "2021-11-23 22:34:14.380 INFO memory - ob2epi: Observation [\"Karen's elephant\", 'AtLocation', \"Karen's tree\", 1637703254.3793077] is now a episodic memory [\"Karen's elephant\", 'AtLocation', \"Karen's tree\", 1637703254.3793077]\n",
      "2021-11-23 22:34:14.380 INFO memory - add: memory entry [\"Karen's elephant\", 'AtLocation', \"Karen's tree\", 1637703254.3793077] added. Now there are in total of 11 memories!\n",
      "2021-11-23 22:34:14.381 INFO environments - episodic_memory_system_to_numbers: The episodic memory system has been converted to a numpy array!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done, info = foo.step(0)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 22:34:15.094 INFO environments - numbers_to_episodic_memories: The numpy array has been converted to episodic memories!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"Richard's toothbrush\", 'AtLocation', \"Richard's suitcase\", 1637703200.0],\n",
       " [\"James's truck\", 'AtLocation', \"James's garage\", 1637703200.0],\n",
       " [\"James's cat\", 'AtLocation', \"James's harbor\", 1637703200.0],\n",
       " [\"Jessica's airplane\", 'AtLocation', \"Jessica's home\", 1637703200.0],\n",
       " [\"William's microwave\", 'AtLocation', \"William's kitchen\", 1637703200.0],\n",
       " [\"Jennifer's bird\", 'AtLocation', \"Jennifer's sky\", 1637703300.0],\n",
       " [\"James's keyboard\", 'AtLocation', \"James's stove\", 1637703300.0],\n",
       " [\"Jennifer's mouse\", 'AtLocation', \"Jennifer's laboratory\", 1637703300.0],\n",
       " [\"Thomas's apple\", 'AtLocation', \"Thomas's fridge\", 1637703300.0],\n",
       " [\"Michael's umbrella\", 'AtLocation', \"Michael's closet\", 1637703300.0],\n",
       " [\"Karen's elephant\", 'AtLocation', \"Karen's tree\", 1637703300.0]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.observation_space.numbers_to_episodic_memories(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryEnv(gym.Env):\n",
    "    \"\"\"Custom Memory environment compatiable with the gym interface.\"\"\"\n",
    "    metadata = {\"render.modes\": [\"console\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        capacity: int,\n",
    "        memory_type: str,\n",
    "        max_history: int = 1024,\n",
    "        semantic_knowledge_path: str = \"./data/semantic-knowledge.json\",\n",
    "        names_path: str = \"./data/top-human-names\",\n",
    "        weighting_mode: str = \"highest\",\n",
    "        commonsense_prob: float = 0.5,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        capacity: memory capacity\n",
    "        memory_type: either episodic or semantic.\n",
    "        max_history: maximum history of observations.\n",
    "        semantic_knowledge_path: path to the semantic knowledge generated from\n",
    "            `collect_data.py`\n",
    "        names_path: The path to the top 20 human name list.\n",
    "        weighting_mode: \"highest\" chooses the one with the highest weight, \"weighted\"\n",
    "            chooses all of them by weight, and null chooses every single one of them\n",
    "            without weighting.\n",
    "        commonsense_prob: the probability of an observation being covered by a\n",
    "            commonsense\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert memory_type in [\"episodic\", \"semantic\"]\n",
    "        self.memory_type = memory_type\n",
    "        self.capacity = capacity\n",
    "        self.oqag = OQAGenerator(\n",
    "            max_history,\n",
    "            semantic_knowledge_path,\n",
    "            names_path,\n",
    "            weighting_mode,\n",
    "            commonsense_prob,\n",
    "        )\n",
    "        n_actions = self.capacity + 1\n",
    "        self.action_space = spaces.Discrete(n_actions)\n",
    "        self.observation_space = MemorySpace(\n",
    "            capacity,\n",
    "            memory_type,\n",
    "            max_history,\n",
    "            semantic_knowledge_path,\n",
    "            names_path,\n",
    "            weighting_mode,\n",
    "            commonsense_prob,\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.oqag.reset()\n",
    "        while True:\n",
    "            ob, question_answer = self.oqag.generate()\n",
    "            mem_epi = M_e.ob2epi(ob)\n",
    "\n",
    "\n",
    "        for idx, ob in enumerate(self.data[self.split]):\n",
    "            self.idx = idx\n",
    "            mem_epi = self.M_dummy.ob2epi(ob)\n",
    "            self.M_dummy.add(mem_epi)\n",
    "\n",
    "            if self.M_dummy.is_kinda_full:\n",
    "                break\n",
    "\n",
    "        assert idx == self.capacity\n",
    "\n",
    "        return self.M_dummy.entries\n",
    "\n",
    "    def step(self, action):\n",
    "        mem_to_forget = self.M_dummy.entries[action]\n",
    "\n",
    "        self.M_dummy.forget(mem_to_forget)\n",
    "\n",
    "        question = select_a_question(self.idx, self.data, self.questions, self.split)\n",
    "\n",
    "        reward, _, _ = self.M_dummy.answer_latest(question)\n",
    "\n",
    "        self.idx += 1\n",
    "        if self.idx == len(self.data[self.split]):\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "            ob = self.data[self.split][self.idx]\n",
    "            mem_epi = self.M_dummy.ob2epi(ob)\n",
    "            self.M_dummy.add(mem_epi)\n",
    "\n",
    "            assert self.M_dummy.is_kinda_full\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return self.M_dummy.entries, reward, done, info\n",
    "\n",
    "    def render(self, mode=\"console\"):\n",
    "        if mode != \"console\":\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            print(self.M_dummy.entries)\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MemoryEnv('episodic', 4, 'train')\n",
    "# If the environment don't follow the interface, an error will be thrown\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MemoryEnv('episodic', 4, 'val')\n",
    "\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "\n",
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(env.action_space.sample())\n",
    "\n",
    "n_steps = 1200\n",
    "\n",
    "for step in range(n_steps):\n",
    "    print(\"Step {}\".format(step + 1))\n",
    "    obs, reward, done, info = env.step(0)\n",
    "    print('obs=', obs, 'reward=', reward, 'done=', done)\n",
    "    env.render()\n",
    "    if done:\n",
    "        print(\"Goal reached!\", \"reward=\", reward)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory import EpisodicMemory\n",
    "\n",
    "capacities = [\n",
    "2,\n",
    "4, 0),\n",
    "    (8, 0),\n",
    "    (16, 0),\n",
    "    (32, 0),\n",
    "    (64, 0),\n",
    "    (128, 0),\n",
    "    (256, 0),\n",
    "    (512, 0),\n",
    "    (1024, 0),\n",
    "]\n",
    "\n",
    "results = {\"train\": {}, \"val\": {}, \"test\": {}}\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "\n",
    "    M_e = EpisodicMemory(capacity[\"episodic\"])\n",
    "    rewards = 0\n",
    "\n",
    "    for step, ob in enumerate(data[split]):\n",
    "        mem_epi = M_e.ob2epi(ob)\n",
    "        M_e.add(mem_epi)\n",
    "        if M_e.is_kinda_full:\n",
    "            if policy[\"forget\"].lower() == \"oldest\":\n",
    "                M_e.forget_oldest()\n",
    "            elif policy[\"forget\"].lower() == \"random\":\n",
    "                M_e.forget_random()\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        question = select_a_question(step, data, questions, split)\n",
    "\n",
    "        if policy[\"answer\"].lower() == \"latest\":\n",
    "            reward, _, _ = M_e.answer_latest(question)\n",
    "        elif policy[\"answer\"].lower() == \"random\":\n",
    "            reward, _, _ = M_e.answer_random(question)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        rewards += reward\n",
    "\n",
    "    results[split][\"rewards\"] = rewards\n",
    "    results[split][\"num_samples\"] = len(data[split])\n",
    "    results[split][\"episodic_memories\"] = M_e.entries\n",
    "\n",
    "    logging.info(f\"results so far: {results}\")\n",
    "\n",
    "logging.info(\"episodic only training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodic only\n",
    "\n",
    "capacity"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7808f786822013b9d5984aa54e12ef6bec326a79c76c0a75cd22ab652610adbd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('explicit-memory': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
